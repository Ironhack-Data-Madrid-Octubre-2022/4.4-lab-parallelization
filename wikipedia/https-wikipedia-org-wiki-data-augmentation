Data augmentation - Wikipedia document.documentElement.className="client-js";RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"277d1b7c-fb87-42ad-a243-b0eadb1af2d3","wgCSPNonce":false,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Data_augmentation","wgTitle":"Data augmentation","wgCurRevisionId":1120100399,"wgRevisionId":1120100399,"wgArticleId":51443362,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: date and year","Articles with short description","Short description is different from Wikidata","Articles needing additional references from September 2020","All articles needing additional references","Machine learning"],"wgPageContentLanguage":"en","wgPageContentModel": "wikitext","wgRelevantPageName":"Data_augmentation","wgRelevantArticleId":51443362,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{"status":{"levels":1}}},"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"watchlist":true,"tagline":false,"nearby":true},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":10000,"wgNoticeProject":"wikipedia","wgVector2022PreviewPages":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":10,"wgULSCurrentAutonym":"English","wgEditSubmitButtonLabelPublish":true,"wgCentralAuthMobileDomain":false,"wgULSPosition":"interlanguage","wgULSisCompactLinksEnabled":true,"wgWikibaseItemId":"Q85014143","GEHomepageSuggestedEditsEnableTopics":true,"wgGETopicsMatchModeEnabled":false,"wgGEStructuredTaskRejectionReasonTextInputEnabled":false}; RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","skins.vector.styles.legacy":"ready","jquery.makeCollapsible.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.wikimediaBadges":"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.legacy.js","mmv.head","mmv.bootstrap.autostart","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.cx.eventlogging.campaigns","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher", "ext.centralauth.centralautologin","ext.popups","ext.uls.compactlinks","ext.uls.interface","ext.growthExperiments.SuggestedEditSession"]; (RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});});});                                           Data augmentation  From Wikipedia, the free encyclopedia    Jump to navigation Jump to search Data analysis technique .mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}This article relies largely or entirely on a single source. Relevant discussion may be found on the talk page. Please help improve this article by introducing  citations to additional sources.Find sources: "Data augmentation" – news · newspapers · books · scholar · JSTOR (September 2020) .mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Part of a series onMachine learningand data mining Problems Classification Regression Clustering dimension reduction density estimation Anomaly detection Data Cleaning AutoML Association rules Structured prediction Feature engineering Feature learning Online learning Reinforcement learning Supervised learning Semi-supervised learning Unsupervised learning Learning to rank Grammar induction  Supervised learning.mw-parser-output .nobold{font-weight:normal}(classification • regression)  Decision trees Ensembles Bagging Boosting Random forest k-NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine (RVM) Support vector machine (SVM)  Clustering BIRCH CURE Hierarchical k-means Fuzzy Expectation–maximization (EM) DBSCAN OPTICS Mean shift  Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD t-SNE SDL  Structured prediction Graphical models Bayes net Conditional random field Hidden Markov  Anomaly detection RANSAC k-NN Local outlier factor Isolation forest  Artificial neural network Autoencoder Cognitive computing Deep learning DeepDream Multilayer perceptron RNN LSTM GRU ESN reservoir computing Restricted Boltzmann machine GAN SOM Convolutional neural network U-Net Transformer Vision Spiking neural network Memtransistor Electrochemical RAM (ECRAM)  Reinforcement learning Q-learning SARSA Temporal difference (TD) Multi-agent Self-play  Learning with humans Active learning Crowdsourcing Human-in-the-loop  Model diagnostics Learning curve  Theory Kernel machines Bias–variance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory  Machine-learning venues NeurIPS ICML ICLR ML JMLR  Related articles Glossary of artificial intelligence List of datasets for machine-learning research Outline of machine learning .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.[1] It is closely related to oversampling in data analysis.  Contents  1 Synthetic oversampling techniques for traditional machine learning 2 Data augmentation for image classification  2.1 Introducing new synthetic images   3 Data augmentation for signal processing  3.1 Biological signals 3.2 Mechanical  signals   4 Data augmentation for speech recognition 5 See also 6 References   Synthetic oversampling techniques for traditional machine learning[edit] .mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: Oversampling and undersampling in data analysis § Oversampling techniques for classification problems Data augmentation for image classification[edit] Introducing new synthetic images[edit] If a dataset is very small, then a version augmented with rotation and mirroring etc. may still not be enough for a given problem. Another solution is the sourcing of entirely new, synthetic images through various techniques, for example the use of generative adversarial networks to create new synthetic images for data augmentation.[1] Additionally, image recognition algorithms show improvement when transferring from images rendered in virtual environments to real-world data.[2]  Data augmentation for signal processing[edit] Residual or block bootstrap can be used for time series augmentation.  Biological signals[edit] Synthetic data augmentation is of paramount importance for machine learning classification, particularly for biological data, which tend to be high dimensional and scarce. The applications of robotic control and augmentation in disabled and able-bodied subjects still rely mainly on subject-specific analyses. Data scarcity is notable in signal processing problems such as for Parkinson's Disease Electromyography signals, which are difficult to source - Zanini, et al. noted that it is possible to use a Generative adversarial network (in particular, a DCGAN) to perform style transfer in order to generate synthetic electromyographic signals that corresponded to those exhibited by sufferers of Parkinson's Disease.[3] The approaches are also important in electroencephalography (brainwaves). Wang, et al. explored the idea of using Deep Convolutional Neural Networks for EEG-Based Emotion Recognition, results show that emotion recognition was improved when data augmentation was used.[4]   A comparison of GPT-2 generated EEG signals (left) and real human brainwaves (right) across "Concentrating", "Relaxed", and "Neutral" mental state classes[5]. It has also been noted that OpenAI's GPT-2 model is capable of learning from, and generating synthetic biological signals such as EEG and EMG.[5] In this study, it was noted that recognition was improved via data augmentation. It was also noted that statistical machine learning models trained on the synthetic domain could classify the human data, and vice versa. In the image, a comparison is given by some examples of EEG produced by the GPT-2 model and a human brain.  A common approach is to generate synthetic signals by re-arranging components of real data. Lotte[6] proposed a method of "Artificial Trial Generation Based on Analogy" where three data examples      x  1   ,  x  2   ,  x  3     {\displaystyle x_{1},x_{2},x_{3}}   provide examples and an artificial      x  s y n t h e t i c     {\displaystyle x_{synthetic}}   is formed which is to      x  3     {\displaystyle x_{3}}   what      x  2     {\displaystyle x_{2}}   is to      x  1     {\displaystyle x_{1}}  . A transformation is applied to      x  1     {\displaystyle x_{1}}   to make it more similar to      x  2     {\displaystyle x_{2}}  , the same transformation is then applied to      x  3     {\displaystyle x_{3}}   which generates      x  s y n t h e t i c     {\displaystyle x_{synthetic}}  . This approach was shown to improve performance of a Linear Discriminant Analysis classifier on three different datasets. Current research shows great impact can be derived from relatively simple techniques. For example, Freer[7] observed that introducing noise into gathered data to form additional data points improved the learning ability of several models which otherwise performed relatively poorly. Tsinganos et al.[8] studied the approaches of magnitude warping, wavelet decomposition, and synthetic surface EMG models (generative approaches) for hand gesture recognition, finding classification performance increases of up to +16% when augmented data was introduced during training. More recently, data augmentation studies have begun to focus on the field of deep learning, more specifically on the ability of generative models to create artificial data which is then introduced during the classification model training process. In 2018, Luo et al.[9] observed that useful EEG signal data could be generated by Conditional Wasserstein Generative Adversarial Networks (GANs) which was then introduced to the training set in a classical train-test learning framework. The authors found classification performance was improved when such techniques were introduced.  Mechanical  signals[edit] The prediction of mechanical signals based on data augmentation brings a new generation of technological innovations, such as new energy dispatch, 5G communication field, and robotics control engineering.[10] In 2022, Yang et al.[10] integrate constraints, optimization and control into a deep network framework based on data augmentation and data pruning with spatio-temporal data correlation, and improve the interpretability, safety and controllability of deep learning in real industrial projects through explicit mathematical programming equations and analytical solutions.  Data augmentation for speech recognition[edit] It has been noted that synthetic data generation of spoken MFCCs can improve the recognition of a speaker from their utterances via transfer learning from synthetic data which has been generated via a Character-level Recurrent Neural Network (RNN).[11]  See also[edit] Oversampling and undersampling in data analysis Generative adversarial network Variational autoencoder Data pre-processing Convolutional neural network Regularization (mathematics) Data preparation Data fusion References[edit] .mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}  ^ a b .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Shorten, Connor; Khoshgoftaar, Taghi M. (2019). "A survey on Image Data Augmentation for Deep Learning". Mathematics and Computers in Simulation. springer. 6: 60. doi:10.1186/s40537-019-0197-0.  ^ Bird, Jordan J; Faria, Diego R; Ekart, Aniko; Ayrosa, Pedro PS (2020-08-30). From simulation to reality: CNN transfer learning for scene classification. 2020 IEEE 10th International Conference on Intelligent Systems (IS). Varna, Bulgaria: IEEE. pp. 619–625.{{cite conference}}:  CS1 maint: date and year (link)  ^ Anicet Zanini, Rafael; Luna Colombini, Esther (2020). "Parkinson's Disease EMG Data Augmentation and Simulation with DCGANs and Style Transfer". Sensors. 20 (9): 2605. Bibcode:2020Senso..20.2605A. doi:10.3390/s20092605. ISSN 1424-8220. PMC 7248755. PMID 32375217.  ^ Wang, Fang; Zhong, Sheng-hua; Peng, Jianfeng; Jiang, Jianmin; Liu, Yan (2018). "Data Augmentation for EEG-Based Emotion Recognition with Deep Convolutional Neural Networks". Multi Media Modeling. Lecture Notes in Computer Science. Vol. 10705. pp. 82–93. doi:10.1007/978-3-319-73600-6_8. ISBN 978-3-319-73599-3. ISSN 0302-9743.  ^ a b Bird, Jordan J.; Pritchard, Michael George; Fratini, Antonio; Ekart, Aniko; Faria, Diego (2021). "Synthetic Biological Signals Machine-generated by GPT-2 improve the Classification of EEG and EMG through Data Augmentation" (PDF). IEEE Robotics and Automation Letters. 6 (2): 3498–3504. doi:10.1109/LRA.2021.3056355. ISSN 2377-3766. S2CID 232373183.  ^ Lotte, Fabien (2015). "Signal Processing Approaches to Minimize or Suppress Calibration Time in Oscillatory Activity-Based Brain–Computer Interfaces" (PDF). Proceedings of the IEEE. 103 (6): 871–890. doi:10.1109/JPROC.2015.2404941. ISSN 0018-9219. S2CID 22472204.  ^ Freer, Daniel; Yang, Guang-Zhong (2020). "Data augmentation for self-paced motor imagery classification with C-LSTM". Journal of Neural Engineering. 17 (1): 016041. Bibcode:2020JNEng..17a6041F. doi:10.1088/1741-2552/ab57c0. hdl:10044/1/75376. ISSN 1741-2552. PMID 31726440. S2CID 208034533.  ^ Tsinganos, Panagiotis; Cornelis, Bruno; Cornelis, Jan; Jansen, Bart; Skodras, Athanassios (2020). "Data Augmentation of Surface Electromyography for Hand Gesture Recognition". Sensors. 20 (17): 4892. Bibcode:2020Senso..20.4892T. doi:10.3390/s20174892. ISSN 1424-8220. PMC 7506981. PMID 32872508.  ^ Luo, Yun; Lu, Bao-Liang (2018). "EEG Data Augmentation for Emotion Recognition Using a Conditional Wasserstein GAN". 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference. Vol. 2018. pp. 2535–2538. doi:10.1109/EMBC.2018.8512865. ISBN 978-1-5386-3646-6. PMID 30440924. S2CID 53105445.  ^ a b Yang, Yang (2022). "Wind speed forecasting with correlation network pruning and augmentation: A two-phase deep learning method". Renewable Energy. 198 (1): 267–282. doi:10.1016/j.renene.2022.07.125. ISSN 0960-1481. S2CID 251511199.  ^ Bird, Jordan J.; Faria, Diego R.; Premebida, Cristiano; Ekart, Aniko; Ayrosa, Pedro P. S. (2020). "Overcoming Data Scarcity in Speaker Identification: Dataset Augmentation with Synthetic MFCCs via Character-level RNN". 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC). pp. 146–151. doi:10.1109/ICARSC49921.2020.9096166. ISBN 978-1-7281-7078-7. S2CID 218832459.   .mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}vteDifferentiable computingGeneral Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic engineering Cable theory Pattern recognition Tensor calculus Computational learning theory Inductive bias Concepts Gradient descent SGD Clustering Regression Overfitting Adversary Attention Convolution Loss functions Backpropagation Normalization Activation Softmax Sigmoid Rectifier Regularization Datasets Augmentation Diffusion Autoregression Programming languages Python Julia Swift Application Machine learning Artificial neural network Deep learning Scientific computing Artificial Intelligence Hardware IPU TPU VPU Memristor SpiNNaker Software library TensorFlow PyTorch Keras Theano JAX ImplementationAudio–visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis Speech recognition Facial recognition AlphaFold DALL-E Verbal Word2vec Transformer BERT LaMDA NMT Project Debater IBM Watson GPT-2 GPT-3 Decisional AlphaGo AlphaZero Q-learning SARSA OpenAI Five Self-driving car MuZero Action selection Robot control People Yoshua Bengio Alex Graves Ian Goodfellow Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng Jürgen Schmidhuber David Silver Organizations DeepMind OpenAI MIT CSAIL Mila Google Brain Meta AI Architectures Neural Turing machine Differentiable neural computer Transformer Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network Residual network Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network   Portals Computer programming Technology  Category Artificial neural networks Machine learning  vteData Augmentation Analysis Archaeology Big Cleansing Collection Compression Corruption Curation Degradation Editing ETL/ELT Extract Transform Load Farming Format management Fusion Integration Integrity Library Lineage Loss Management Migration Mining Philanthropy Pre-processing Preservation Protection (privacy) Publishing Recovery Reduction Retention Quality Science Scraping Scrubbing Security Stewardship Storage Validation Warehouse Wrangling/munging      Retrieved from "https://en.wikipedia.org/w/index.php?title=Data_augmentation&oldid=1120100399" Categories: Machine learningHidden categories: CS1 maint: date and yearArticles with short descriptionShort description is different from WikidataArticles needing additional references from September 2020All articles needing additional references    Navigation menu    Personal tools   Not logged inTalkContributionsCreate accountLog in      Namespaces   ArticleTalk      English          Views   ReadEditView history      More         Search                    Navigation   Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate     Contribute   HelpLearn to editCommunity portalRecent changesUpload file     Tools   What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageWikidata item     Print/export   Download as PDFPrintable version     Languages   فارسی한국어 Edit links        This page was last edited on 5 November 2022, at 04:25 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License 3.0; additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.   Privacy policy About Wikipedia Disclaimers Contact Wikipedia Mobile view Developers Statistics Cookie statement       (RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.527","walltime":"0.679","ppvisitednodes":{"value":1387,"limit":1000000},"postexpandincludesize":{"value":104126,"limit":2097152},"templateargumentsize":{"value":1751,"limit":2097152},"expansiondepth":{"value":12,"limit":100},"expensivefunctioncount":{"value":3,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":53989,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  537.907      1 -total"," 43.56%  234.334      1 Template:Reflist"," 29.27%  157.467      7 Template:Cite_journal"," 13.65%   73.440      1 Template:One_source"," 12.94%   69.588      3 Template:Navbox"," 12.65%   68.064      1 Template:Ambox"," 12.39%   66.670      1 Template:Differentiable_computing"," 12.22%   65.744      1 Template:Short_description"," 11.08%   59.622      1 Template:Machine_learning"," 10.64%   57.260      1 Template:Sidebar_with_collapsible_lists"]},"scribunto":{"limitreport-timeusage":{"value":"0.334","limit":"10.000"},"limitreport-memusage":{"value":7546192,"limit":52428800}},"cachereport":{"origin":"mw1360","timestamp":"20221105042538","ttl":1814400,"transientcontent":false}}});}); {"@context":"https:\/\/schema.org","@type":"Article","name":"Data augmentation","url":"https:\/\/en.wikipedia.org\/wiki\/Data_augmentation","sameAs":"http:\/\/www.wikidata.org\/entity\/Q85014143","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q85014143","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2016-08-28T14:38:11Z","dateModified":"2022-11-05T04:25:36Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/f\/fe\/Kernel_Machine.svg","headline":"creation of more data based on previously collected data to enhance the performance of a statistical model"}{"@context":"https:\/\/schema.org","@type":"Article","name":"Data augmentation","url":"https:\/\/en.wikipedia.org\/wiki\/Data_augmentation","sameAs":"http:\/\/www.wikidata.org\/entity\/Q85014143","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q85014143","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2016-08-28T14:38:11Z","dateModified":"2022-11-05T04:25:36Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/f\/fe\/Kernel_Machine.svg","headline":"creation of more data based on previously collected data to enhance the performance of a statistical model"} (RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":92,"wgHostname":"mw1435"});});